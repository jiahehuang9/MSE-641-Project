{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import umap\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from google.colab import drive\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from cuml import UMAP, KMeans, DBSCAN\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Clustering and visualization",
   "id": "c61e3df73bb1ad89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load data\n",
    "in_path = \"/content/drive/MyDrive/MSE 641 Project Data/wildchat_work_only.jsonl\"\n",
    "\n",
    "prompts = []\n",
    "responses = []\n",
    "texts = []\n",
    "\n",
    "with open(in_path, \"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    obj = json.loads(line)\n",
    "    if \"conversation\" in obj:\n",
    "      conv = obj[\"conversation\"]\n",
    "      if \"Prompt:\" in conv and \"Response:\" in conv:\n",
    "        prompt_part = conv.split(\"Prompt:\")[1].split(\"Response:\")[0].strip()\n",
    "        response_part = conv.split(\"Response:\")[1].strip()\n",
    "        prompts.append(prompt_part)\n",
    "        responses.append(response_part)\n",
    "        texts.append(prompt_part + \" \" + response_part)\n",
    "\n",
    "# BERT embedding\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(texts, batch_size=64, show_progress_bar=True)\n",
    "\n",
    "SVD_DIM = 100\n",
    "svd = TruncatedSVD(n_components=SVD_DIM, random_state=42)\n",
    "X_svd = svd.fit_transform(embeddings)\n",
    "\n",
    "# Parameters\n",
    "umap_neighbors = [30]\n",
    "umap_dims = [30]\n",
    "k_range = [5, 10, 20]\n",
    "dbscan_eps = 1.2\n",
    "dbscan_min_samples = 15\n",
    "\n",
    "results = []\n",
    "best_k_results = {}\n",
    "\n",
    "for umap_dim in umap_dims:\n",
    "  for umap_nn in umap_neighbors:\n",
    "    umap_model = umap.UMAP(n_components=umap_dim, n_neighbors=umap_nn, random_state=42)\n",
    "    X_umap = umap_model.fit_transform(X_svd)\n",
    "\n",
    "    for k in k_range:\n",
    "      kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "      kmeans_labels = kmeans.fit_predict(X_umap)\n",
    "\n",
    "      final_labels = np.full(len(X_umap), -1)\n",
    "      for i in range(k):\n",
    "        idx = (kmeans_labels == i)\n",
    "        if np.sum(idx) == 0:\n",
    "          continue\n",
    "        subcluster = X_umap[idx]\n",
    "        dbscan = DBSCAN(eps=dbscan_eps, min_samples=dbscan_min_samples)\n",
    "        sub_labels = dbscan.fit_predict(subcluster)\n",
    "        for j, sub_label in enumerate(sub_labels):\n",
    "          global_idx = np.where(idx)[0][j]\n",
    "          if sub_label >= 0:\n",
    "            final_labels[global_idx] = i * 1000 + sub_label\n",
    "          else:\n",
    "            final_labels[global_idx] = -1\n",
    "\n",
    "      valid = final_labels >= 0\n",
    "      X_valid = X_umap[valid]\n",
    "      labels_valid = final_labels[valid]\n",
    "      if len(np.unique(labels_valid)) > 1:\n",
    "        sil = silhouette_score(X_valid, labels_valid)\n",
    "        ch = calinski_harabasz_score(X_valid, labels_valid)\n",
    "        db = davies_bouldin_score(X_valid, labels_valid)\n",
    "      else:\n",
    "        sil, ch, db = float('nan'), float('nan'), float('nan')\n",
    "\n",
    "      results.append({\n",
    "        'umap_dim': umap_dim,\n",
    "        'umap_nn': umap_nn,\n",
    "        'k': k,\n",
    "        'dbscan_eps': dbscan_eps,\n",
    "        'dbscan_min_samples': dbscan_min_samples,\n",
    "        'silhouette': sil,\n",
    "        'calinski_harabasz': ch,\n",
    "        'davies_bouldin': db,\n",
    "        'n_clusters': len(np.unique(labels_valid)),\n",
    "      })\n",
    "\n",
    "      if k not in best_k_results or sil > best_k_results[k][\"silhouette\"]:\n",
    "        best_k_results[k] = {\n",
    "          \"silhouette\": sil,\n",
    "          \"dim\": umap_dim,\n",
    "          \"nn\": umap_nn,\n",
    "          \"k\": k,\n",
    "          \"labels\": final_labels,\n",
    "          \"X_umap\": X_umap\n",
    "        }\n",
    "\n",
    "# Save and Plot for Best Per-k Results\n",
    "for k, result in best_k_results.items():\n",
    "  X_umap = result[\"X_umap\"]\n",
    "  labels = result[\"labels\"]\n",
    "  dim = result[\"dim\"]\n",
    "  nn = result[\"nn\"]\n",
    "\n",
    "  joblib.dump(X_umap, f\"/content/drive/MyDrive/MSE 641 Project Data/bert_umap_matrix_k{k}_best_work.pkl\")\n",
    "  joblib.dump(labels, f\"/content/drive/MyDrive/MSE 641 Project Data/bert_kmeans_labels_k{k}_best_work.pkl\")\n",
    "\n",
    "  if X_umap.shape[1] > 2:\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X_2d = svd.fit_transform(X_umap)\n",
    "  else:\n",
    "    X_2d = X_umap\n",
    "\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=labels, cmap='tab20', s=10, alpha=0.7)\n",
    "  plt.title(f\"BERT + UMAP({dim},{nn}) + KMeans(k={k}) + DBSCAN(1.2,15)\")\n",
    "  plt.xlabel(\"Component 1\")\n",
    "  plt.ylabel(\"Component 2\")\n",
    "  plt.grid(True, linestyle='--', alpha=0.3)\n",
    "  plt.colorbar(scatter, label=\"Cluster ID\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  plt.savefig(f\"/content/drive/MyDrive/MSE 641 Project Data/bert_kmeans_best_k{k}_plot_work.png\")\n",
    "  plt.close()\n",
    "\n",
    "# Save evaluation summary\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_path = \"/content/drive/MyDrive/MSE 641 Project Data/bert_kmeans_dbscan_metrics_best_per_k_work.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n"
   ],
   "id": "e8555934313b7be0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Clustering result example",
   "id": "17587b977acd7539"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Display clustering results with  10 sample texts for each cluster in best_k_results\n",
    "num_samples_per_cluster = 10  \n",
    "\n",
    "for k, result in best_k_results.items():\n",
    "  print(f\"\\n--- Results for k = {k} ---\")\n",
    "  labels = result[\"labels\"]\n",
    "  X_umap = result[\"X_umap\"]\n",
    "  cluster_ids = set(labels)\n",
    "  cluster_ids.discard(-1)\n",
    "\n",
    "  data = pd.DataFrame({\n",
    "    \"label\": labels,\n",
    "    \"text\": texts\n",
    "  })\n",
    "\n",
    "  for cluster in sorted(cluster_ids):\n",
    "    cluster_texts = data[data[\"label\"] == cluster][\"text\"].tolist()\n",
    "    print(f\"\\nCluster {cluster} (size={len(cluster_texts)}):\")\n",
    "    if len(cluster_texts) > num_samples_per_cluster:\n",
    "      sample_texts = random.sample(cluster_texts, num_samples_per_cluster)\n",
    "    else:\n",
    "      sample_texts = cluster_texts\n",
    "\n",
    "    for i, text in enumerate(sample_texts):\n",
    "      snippet = text[:300].replace('\\n', ' ')\n",
    "      print(f\"Sample {i+1}: {snippet}...\")\n",
    "      "
   ],
   "id": "1ea0d423a99200c6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
